import os
import asyncio
import logging
from dotenv import load_dotenv
from aiogram import Bot, Dispatcher, types, F
from aiogram.types import CallbackQuery, InlineKeyboardMarkup, InlineKeyboardButton
from aiogram.filters import CommandStart
from aiogram.fsm.context import FSMContext
from aiogram.fsm.state import State, StatesGroup
from aiogram.fsm.storage.memory import MemoryStorage

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(level=logging.INFO)
load_dotenv()

TOKEN = os.getenv('TELEGRAM_TOKEN')
bot = Bot(token=TOKEN)
storage = MemoryStorage()
dp = Dispatcher(storage=storage)

class AIChoice(StatesGroup):
    waiting_query = State()

# ========== –ú–ï–ù–Æ ==========
def get_main_keyboard():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="ü§ñ Grok", callback_data="ai_grok")],
        [InlineKeyboardButton(text="üí¨ ChatGPT", callback_data="ai_chatgpt")],
        [InlineKeyboardButton(text="‚≠ê Gemini", callback_data="ai_gemini")],
        [InlineKeyboardButton(text="üîç Perplexity", callback_data="ai_perplexity")],
        [InlineKeyboardButton(text="‚öôÔ∏è Copilot", callback_data="ai_copilot")],
        [InlineKeyboardButton(text="üíª –ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è", callback_data="cat_programming")],
        [InlineKeyboardButton(text="üìö –ù–∞–≤—á–∞–Ω–Ω—è", callback_data="cat_learning")],
    ])

def get_programming_keyboard():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üöÄ Codeium", callback_data="ai_codeium")],
        [InlineKeyboardButton(text="üîß Codex", callback_data="ai_codex")],
        [InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="back_main")]
    ])

def get_learning_keyboard():
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üìù Eduaide", callback_data="ai_eduaide")],
        [InlineKeyboardButton(text="üéì Khanmigo", callback_data="ai_khanmigo")],
        [InlineKeyboardButton(text="‚óÄÔ∏è –ù–∞–∑–∞–¥", callback_data="back_main")]
    ])

def get_response_keyboard(msg_id: int):
    return InlineKeyboardMarkup(inline_keyboard=[
        [InlineKeyboardButton(text="üîÑ –Ü–Ω—à–∏–π AI", callback_data=f"redirect_{msg_id}")],
        [InlineKeyboardButton(text="üìã –ö–æ–ø—ñ—é–≤–∞—Ç–∏", callback_data=f"copy_{msg_id}")],
        [InlineKeyboardButton(text="üè† –ú–µ–Ω—é", callback_data="back_main")]
    ])

# ========== API –ö–õ–Ü–Ñ–ù–¢–ò ==========
client_openai = None
gemini_model = None
perplexity_client = None

def init_clients():
    global client_openai, gemini_model, perplexity_client
    
    try:
        import openai
        if os.getenv('OPENAI_API_KEY'):
            client_openai = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
    except ImportError:
        logging.warning("OpenAI –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    try:
        import google.generativeai as genai
        if os.getenv('GEMINI_API_KEY'):
            genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
            gemini_model = genai.GenerativeModel('gemini-1.5-flash')
    except ImportError:
        logging.warning("Google Generative AI –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
    
    try:
        from perplexity import Perplexity  # –û—Ñ—ñ—Ü—ñ–π–Ω–∏–π SDK
        if os.getenv('PERPLEXITY_API_KEY'):
            perplexity_client = Perplexity(api_key=os.getenv('PERPLEXITY_API_KEY'))
    except ImportError:
        logging.warning("Perplexity SDK –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ ‚Äî –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ requests fallback")

# ========== QUERY TO AI ==========
async def query_ai(ai_type: str, query: str):
    try:
        if ai_type == "grok":
            from openai import OpenAI
            client = OpenAI(base_url="https://api.x.ai/v1", api_key=os.getenv('XAI_API_KEY'))
            resp = client.chat.completions.create(
                model="grok-beta",
                messages=[{"role": "user", "content": query}]
            )
            return resp.choices[0].message.content
        
        elif ai_type == "chatgpt" and client_openai:
            resp = client_openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": query}]
            )
            return resp.choices[0].message.content
        
        elif ai_type == "gemini" and gemini_model:
            resp = gemini_model.generate_content(query)
            return resp.text
        
        elif ai_type == "perplexity":
            if perplexity_client:
                # –û—Ñ—ñ—Ü—ñ–π–Ω–∏–π SDK
                response = perplexity_client.chat.completions.create(
                    model="llama-3.1-sonar-small-128k-online",
                    messages=[{"role": "user", "content": query}]
                )
                return response.choices[0].message.content
            else:
                # Fallback —á–µ—Ä–µ–∑ requests (—è–∫—â–æ SDK –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ)
                import requests
                headers = {
                    "Authorization": f"Bearer {os.getenv('PERPLEXITY_API_KEY')}",
                    "Content-Type": "application/json"
                }
                data = {
                    "model": "llama-3.1-sonar-small-128k-online",
                    "messages": [{"role": "user", "content": query}]
                }
                resp = requests.post("https://api.perplexity.ai/chat/completions", headers=headers, json=data)
                if resp.status_code == 200:
                    return resp.json()["choices"][0]["message"]["content"]
                else:
                    return "‚ùå Perplexity –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä –∫–ª—é—á"
        
        elif ai_type == "copilot":
            return f"ü§ñ Copilot: –ê–Ω–∞–ª—ñ–∑ –∑–∞–ø–∏—Ç—É '{query[:50]}...' (—Å–∏–º—É–ª—è—Ü—ñ—è)"
        
        elif ai_type == "codeium":
            # –°–∏–º—É–ª—è—Ü—ñ—è (API Codeium –ø–æ—Ç—Ä–µ–±—É—î auth)
            return "```python\n# Generated by Codeium\nprint('Hello World!')\ndef hello():\n    return '–ü—Ä–∏–≤—ñ—Ç!'\n```"
        
        elif ai_type == "eduaide":
            return f"üìö **Eduaide —É—Ä–æ–∫:** {query}\n\n1. –í—Å—Ç—É–ø\n2. –ü—Ä–∞–∫—Ç–∏–∫–∞\n3. –¢–µ—Å—Ç"
        
        elif ai_type == "codex":
            # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ OpenAI –¥–ª—è –∫–æ–¥-–≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó
            if client_openai:
                resp = client_openai.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": f"–ù–∞–ø–∏—à–∏ –∫–æ–¥ –¥–ª—è: {query}"}]
                )
                return f"```python\n{resp.choices[0].message.content}\n```"
            return "```python\n# Codex —Å–∏–º—É–ª—è—Ü—ñ—è\npass\n```"
        
        elif ai_type == "khanmigo":
            return f"üéì **Khanmigo:** –ü–æ—è—Å–Ω–µ–Ω–Ω—è {query} –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏"
        
        return f"‚ùå {ai_type} –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∏–π ‚Äî –ø–µ—Ä–µ–≤—ñ—Ä API –∫–ª—é—á —É .env"
        
    except Exception as e:
        logging.error(f"–ü–æ–º–∏–ª–∫–∞ {ai_type}: {e}")
        return f"‚ùå –ü–æ–º–∏–ª–∫–∞ {ai_type}: {str(e)}"

# ========== HANDLERS ==========
@dp.message(CommandStart())
async def start_handler(message: types.Message, state: FSMContext):
    await message.answer("ü§ñ **Multi AI Bot**\n–û–±–µ—Ä–∏ AI –¥–ª—è –∑–∞–ø–∏—Ç—É:", 
                        reply_markup=get_main_keyboard(), parse_mode="Markdown")
    await state.set_state(AIChoice.waiting_query)

@dp.message(F.text, AIChoice.waiting_query)
async def handle_query(message: types.Message, state: FSMContext):
    data = await state.get_data()
    current_ai = data.get("current_ai")
    
    if not current_ai:
        await message.answer("‚ö†Ô∏è –°–ø–æ—á–∞—Ç–∫—É –æ–±–µ—Ä–∏ AI –∑ –º–µ–Ω—é!")
        return
    
    await message.answer("‚è≥ –û–±—Ä–æ–±–ª—è—é –∑–∞–ø–∏—Ç...")
    
    response = await query_ai(current_ai, message.text)
    msg = await message.answer(
        f"**{current_ai.upper()}**\n\n{response}",
        reply_markup=get_response_keyboard(message.message_id),
        parse_mode="Markdown"
    )

@dp.callback_query(F.data.startswith("ai_"))
async def ai_selected(callback: CallbackQuery, state: FSMContext):
    ai_type = callback.data.split("_")[1]
    await state.update_data(current_ai=ai_type)
    await callback.message.edit_text(
        f"‚úÖ –í–∏–±—Ä–∞–Ω–æ **{ai_type}**\n\n–ù–∞–ø–∏—à–∏ –∑–∞–ø–∏—Ç:",
        reply_markup=None,
        parse_mode="Markdown"
    )
    await callback.answer()

@dp.callback_query(F.data.startswith("cat_"))
async def category_selected(callback: CallbackQuery):
    cat = callback.data.split("_")[1]
    if cat == "programming":
        await callback.message.edit_text("üíª **–ü—Ä–æ–≥—Ä–∞–º—É–≤–∞–Ω–Ω—è**", reply_markup=get_programming_keyboard())
    elif cat == "learning":
        await callback.message.edit_text("üìö **–ù–∞–≤—á–∞–Ω–Ω—è**", reply_markup=get_learning_keyboard())
    await callback.answer()

@dp.callback_query(F.data == "back_main")
async def back_main(callback: CallbackQuery):
    await callback.message.edit_text("üè† **–ì–æ–ª–æ–≤–Ω–µ –º–µ–Ω—é**", reply_markup=get_main_keyboard())
    await callback.answer()

@dp.callback_query(F.data.startswith("copy_"))
async def copy_response(callback: CallbackQuery):
    # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä—ñ –∫–Ω–æ–ø–∫–∏ –¥–ª—è —á–∏—Å—Ç–æ—Ç–∏
    await callback.message.edit_reply_markup(reply_markup=None)
    await callback.message.reply(f"üìã **–î–ª—è –∫–æ–ø—ñ—é–≤–∞–Ω–Ω—è:**\n```{callback.message.text}```", parse_mode="Markdown")
    await callback.answer("–°–∫–æ–ø—ñ–π–æ–≤–∞–Ω–æ! (Ctrl+C)")

@dp.callback_query(F.data.startswith("redirect_"))
async def redirect_ai(callback: CallbackQuery, state: FSMContext):
    await callback.message.edit_text("üîÑ –û–±–µ—Ä–∏ —ñ–Ω—à–∏–π AI –¥–ª—è –ø–µ—Ä–µ–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:", reply_markup=get_main_keyboard())
    await state.set_data({"context": callback.message.text})  # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç
    await callback.answer()

# ========== MAIN ==========
async def main():
    init_clients()
    print("üöÄ Bot starting...")
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())